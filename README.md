

## **README.md**

# üß† RAG Q&A Support Bot

This project is a **Retrieval-Augmented Generation (RAG)** pipeline that builds an intelligent **Q&A support bot** using your website‚Äôs content.

It crawls a website, cleans the text, generates embeddings, stores them in a **vector database (FAISS)**, and exposes a **FastAPI endpoint** that answers user questions **only from the crawled content**.

---

## üöÄ Features

‚úÖ Crawl and extract text content from any website
‚úÖ Clean and chunk text into manageable pieces
‚úÖ Generate text embeddings using OpenAI models
‚úÖ Store embeddings in a FAISS vector database for fast similarity search
‚úÖ Retrieve relevant chunks based on user queries
‚úÖ Use a language model to answer questions grounded in retrieved content
‚úÖ Expose an API endpoint (`/ask`) to integrate the bot anywhere (chat, UI, etc.)

---

## üß© Project Structure

```
rag_bot/
‚îÇ
‚îú‚îÄ‚îÄ crawler.py            # Crawl website and save raw text
‚îú‚îÄ‚îÄ clean_text.py         # Clean text and split into chunks
‚îú‚îÄ‚îÄ embeddings.py         # Generate embeddings for text chunks
‚îú‚îÄ‚îÄ vector_store.py       # Store embeddings in FAISS
‚îú‚îÄ‚îÄ retriever.py          # Retrieve relevant chunks and generate answers
‚îú‚îÄ‚îÄ api.py                # FastAPI endpoint for Q&A
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ raw_text.json         # Crawled website text
    ‚îú‚îÄ‚îÄ embeddings.json       # Embeddings for chunks
    ‚îú‚îÄ‚îÄ embeddings.index      # FAISS index file
    ‚îî‚îÄ‚îÄ index_to_chunk.json   # Mapping of index -> text chunks
```

---

## ‚öôÔ∏è Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/rag-bot.git
cd rag-bot
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## üîë Environment Setup

Set your OpenAI API key as an environment variable:

**Linux/macOS:**

```bash
export OPENAI_API_KEY="your_api_key_here"
```

**Windows (PowerShell):**

```bash
setx OPENAI_API_KEY "your_api_key_here"
```

---

## üß± Step-by-Step Workflow

### **1Ô∏è‚É£ Crawl the Website**

Edit `crawler.py` and add your target URLs:

```python
urls = [
    "https://example.com",
    "https://example.com/about"
]
```

Then run:

```bash
python crawler.py
```

‚û°Ô∏è This will create `data/raw_text.json` containing the website‚Äôs text.

---

### **2Ô∏è‚É£ Clean and Chunk Text**

```bash
python clean_text.py
```

‚û°Ô∏è This removes unwanted characters and splits text into smaller chunks.

---

### **3Ô∏è‚É£ Generate Embeddings**

```bash
python embeddings.py
```

‚û°Ô∏è Uses OpenAI‚Äôs embedding model (`text-embedding-3-small`) to create vector representations of each chunk.

---

### **4Ô∏è‚É£ Build the Vector Store**

```bash
python vector_store.py
```

‚û°Ô∏è Stores all embeddings in a **FAISS** index for fast retrieval.

---

### **5Ô∏è‚É£ Run the API**

```bash
python api.py
```

This starts a FastAPI server at:

üëâ [http://127.0.0.1:8000/ask](http://127.0.0.1:8000/ask)

---

### **6Ô∏è‚É£ Ask Questions**

Use `curl` or Postman to send questions:

```bash
curl -X POST "http://127.0.0.1:8000/ask" \
-H "Content-Type: application/json" \
-d '{"question":"What is this website about?"}'
```

**Example Response:**

```json
{
  "answer": "This website provides tutorials and guides about..."
}
```

---

## ‚ö° Example Use Cases

* Support bot for your company‚Äôs documentation site
* Knowledge retrieval system for internal portals
* FAQ assistant for your product website
* Conversational interface for static HTML documentation

---

## üß† How It Works (RAG Pipeline)

1. **Crawling** ‚Üí Collects website content
2. **Preprocessing** ‚Üí Cleans and chunks text
3. **Embedding** ‚Üí Converts text to vector form
4. **Vector Store** ‚Üí Stores and searches text semantically
5. **Retrieval + Generation** ‚Üí Combines search results with LLM responses

---

## üß∞ Tech Stack

| Component        | Technology           |
| ---------------- | -------------------- |
| Language         | Python 3.10+         |
| Web Framework    | FastAPI              |
| Vector Database  | FAISS                |
| LLM & Embeddings | OpenAI API           |
| Data Processing  | BeautifulSoup, NumPy |

---

## üîç Troubleshooting

* **Low-quality answers?**

  * Try smaller chunks (e.g., 300‚Äì500 tokens).
  * Use a better model like `gpt-4.1` for answer generation.

* **API key not found?**

  * Check your environment variable setup.

* **Unicode errors in crawling?**

  * Add `.encode('utf-8', errors='ignore').decode('utf-8')` while saving text.

---

## üåü Future Enhancements

* Support for multi-page crawling (automatic link traversal)
* Integration with Pinecone or Chroma DB
* Streamlit or React frontend
* Context caching for faster responses
* Support for file uploads (PDFs, docs)

---


